<!doctype html><html lang=en data-figures class=page><head><title>TCP 接收报文 流程分析 | My Blog</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta name=description content="TCP接收报文流程分析

  

    
      
        
        
        
        
        
        
    "><meta name=twitter:card content="summary"><meta name=twitter:creator content><meta name=twitter:title content="TCP 接收报文 流程分析"><meta name=twitter:image content="https://songronghu.github.io/"><meta property="og:url" content="https://songronghu.github.io/posts/2025-12-04/"><meta property="og:title" content="TCP 接收报文 流程分析"><meta property="og:description" content="TCP接收报文流程分析

  

    
      
        
        
        
        
        
        
    "><meta property="og:image" content="https://songronghu.github.io/"><meta name=keywords content="Blog"><link rel=apple-touch-icon sizes=180x180 href=https://songronghu.github.io/icons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://songronghu.github.io/icons/favicon-32x32.png><link rel=manifest href=https://songronghu.github.io/icons/site.webmanifest><link rel=canonical href=https://songronghu.github.io/posts/2025-12-04/><link rel=preload href=https://songronghu.github.io/css/styles.dc38388a8f0b890e788bd3a99b7495d14e7d5ac4359ed3b49abeb778497863b284ad4cc7e496ef58c84139295f9bafed82f5a41345eda86bd2d429cccb7c2596.css integrity="sha512-3Dg4io8LiQ54i9Opm3SV0U59WsQ1ntO0mr63eEl4Y7KErUzH5JbvWMhBOSlfm6/tgvWkE0XtqGvS1CnMy3wllg==" as=style crossorigin=anonymous><link rel=preload href=https://songronghu.github.io/en/js/bundle.9f41e8957746dbf4000a4ae0202eee34b28fe11dddf9f34fa79df3b517193fdf6bcc548f3b5eebbd24d9fdb6a28b171d1eb864b71df27f3466ad183206aa8af4.js as=script integrity="sha512-n0HolXdG2/QACkrgIC7uNLKP4R3d+fNPp53ztRcZP99rzFSPO17rvSTZ/baiixcdHrhktx3yfzRmrRgyBqqK9A==" crossorigin=anonymous><link rel=stylesheet type=text/css href=https://songronghu.github.io/css/styles.dc38388a8f0b890e788bd3a99b7495d14e7d5ac4359ed3b49abeb778497863b284ad4cc7e496ef58c84139295f9bafed82f5a41345eda86bd2d429cccb7c2596.css integrity="sha512-3Dg4io8LiQ54i9Opm3SV0U59WsQ1ntO0mr63eEl4Y7KErUzH5JbvWMhBOSlfm6/tgvWkE0XtqGvS1CnMy3wllg==" crossorigin=anonymous></head><body data-code=100 data-lines=false id=documentTop data-lang=en><header class=nav_header><nav class=nav><a href=https://songronghu.github.io/ class="nav_brand nav_item" title="My Blog">My Blog<div class=nav_close><div><svg class="icon"><title>open-menu</title><use xlink:href="#open-menu"/></svg>
<svg class="icon"><title>closeme</title><use xlink:href="#closeme"/></svg></div></div></a><div class='nav_body nav_body_left'><div class=follow><div class=color_mode><input type=checkbox class=color_choice id=mode></div></div></div></nav></header><main><div class="grid-inverse wrap content"><article class=post_content><h1 class=post_title>TCP 接收报文 流程分析</h1><div class=post_meta><span><svg class="icon"><title>calendar</title><use xlink:href="#calendar"/></svg>
</span><span class=post_date>Dec 4, 2025
</span><span class=post_time>· 8 min read</span><span>&nbsp;· <a href=https://songronghu.github.io/tags/blog/ title=Blog class="post_tag button button_translucent">Blog
</a></span><span class=page_only>&nbsp;·<div class=post_share>Share on:
<a href="https://twitter.com/intent/tweet?text=TCP%20%e6%8e%a5%e6%94%b6%e6%8a%a5%e6%96%87%20%e6%b5%81%e7%a8%8b%e5%88%86%e6%9e%90&url=https%3a%2f%2fsongronghu.github.io%2fposts%2f2025-12-04%2f&tw_p=tweetbutton" class=twitter title="Share on Twitter" target=_blank rel=nofollow><svg class="icon"><title>twitter</title><use xlink:href="#twitter"/></svg>
</a><a href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fsongronghu.github.io%2fposts%2f2025-12-04%2f&t=TCP%20%e6%8e%a5%e6%94%b6%e6%8a%a5%e6%96%87%20%e6%b5%81%e7%a8%8b%e5%88%86%e6%9e%90" class=facebook title="Share on Facebook" target=_blank rel=nofollow><svg class="icon"><title>facebook</title><use xlink:href="#facebook"/></svg>
</a><a href=#linkedinshare id=linkedinshare class=linkedin title="Share on LinkedIn" rel=nofollow><svg class="icon"><title>linkedin</title><use xlink:href="#linkedin"/></svg>
</a><a href=https://songronghu.github.io/posts/2025-12-04/ title="Copy Link" class="link link_yank"><svg class="icon"><title>copy</title><use xlink:href="#copy"/></svg></a></div></span></div><div class=post_toc><h2>Overview</h2><nav id=TableOfContents><ul><li><a href=#tcp接收报文流程分析>TCP接收报文流程分析</a><ul><li><a href=#一-整体流程概览>一、整体流程概览</a></li><li><a href=#二-四个队列的作用与位置>二、四个队列的作用与位置</a></li><li><a href=#三-详细步骤解析-对应图中序号>三、详细步骤解析（对应图中序号）</a></li><li><a href=#四-阻塞与非阻塞场景对比>四、阻塞与非阻塞场景对比</a></li><li><a href=#五-内核中主要结构对应关系>五、内核中主要结构对应关系</a></li><li><a href=#六-总结类比>六、总结类比</a></li></ul></li><li><a href=#一-总体流程>一、总体流程</a></li><li><a href=#二-按阶段详解>二、按阶段详解</a><ul><li><a href=#a-dot-网卡-softirq-napi>A. 网卡 → softirq / NAPI</a></li><li><a href=#b-dot-ip-层-ipv4-ipv6>B. IP 层（IPv4/IPv6）</a></li><li><a href=#c-dot-tcp-层-socket-查找-and-状态处理>C. TCP 层：socket 查找 & 状态处理</a></li><li><a href=#d-dot-数据入队-tcp-rcv-established-tcp-data-queue-关键>D. 数据入队： <code>tcp_rcv_established()</code> / <code>tcp_data_queue()</code> （关键）</a></li><li><a href=#e-dot-唤醒用户态-sk-data-ready-sock-queue-rcv-skb>E. 唤醒用户态（ <code>sk_data_ready</code> / <code>sock_queue_rcv_skb</code> ）</a></li><li><a href=#f-dot-用户态读取-tcp-recvmsg-recv-返回>F. 用户态读取： <code>tcp_recvmsg()</code> / <code>recv()</code> 返回</a></li><li><a href=#完整调用链>完整调用链</a></li></ul></li><li><a href=#三-阻塞-vs-非阻塞-内核里的差别-流程上哪些点不一样>三、阻塞 vs 非阻塞：内核里的差别（流程上哪些点不一样）</a><ul><li><a href=#阻塞-socket-默认>阻塞 socket（默认）</a></li><li><a href=#非阻塞-socket-o-nonblock>非阻塞 socket（=O_NONBLOCK=）</a></li></ul></li><li><a href=#四-源码定位>四、源码定位</a></li><li><a href=#五-补充说明>五、补充说明</a></li><li><a href=#六-关于原文-高性能网络编程3-tcp消息的接收-的进一步理解>六、关于原文 高性能网络编程3-tcp消息的接收 的进一步理解</a><ul><li><a href=#原文描述如下>原文描述如下：</a></li><li><a href=#一-tcp-报文接收的完整路径-总体流程>一、TCP 报文接收的完整路径（总体流程）</a></li><li><a href=#二-四个关键队列的角色-5-dot-15-内核视角>二、四个关键队列的角色（5.15 内核视角）</a></li><li><a href=#三-结合图中-13-个步骤的逐步解释-以-5-dot-15-内核为参考>三、结合图中 13 个步骤的逐步解释（以 5.15 内核为参考）</a></li><li><a href=#四-四个队列之间的交互总结图>四、四个队列之间的交互总结图</a></li><li><a href=#五-阻塞-vs-非阻塞-recv-的差异>五、阻塞 vs 非阻塞 recv 的差异</a></li><li><a href=#六-prequeue-的现状-linux-5-dot-15>六、prequeue 的现状（Linux 5.15）</a></li><li><a href=#七-总结>七、总结</a></li><li><a href=#简明描述13个步骤>简明描述13个步骤：</a></li><li><a href=#背景区别>背景区别</a></li><li><a href=#简化理解的流程-tcp-low-latency-0>简化理解的流程（tcp_low_latency = 0）</a></li><li><a href=#总体差异总结>总体差异总结</a></li></ul></li></ul></nav></div><div class=post_body><h2 id=tcp接收报文流程分析>TCP接收报文流程分析</h2><p><figure><picture><img loading=lazy decoding=async alt class="image_figure image_internal image_unprocessed" src=https://songronghu.github.io/images/2025-12-04_2025_12_19_12_05_37.png></picture></figure><a href=https://www.taohui.pub/2016/01/26/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B3-tcp%E6%B6%88%E6%81%AF%E7%9A%84%E6%8E%A5%E6%94%B6/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B3/>引用：TCP消息的接收</a></p><h3 id=一-整体流程概览>一、整体流程概览</h3><p><strong>服务器端接收 TCP 报文</strong> 的内核逻辑。 大体过程如下：</p><ol><li><strong>网卡收到报文</strong> → 交给内核协议栈。</li><li><strong>TCP 层</strong> 检查序列号是否在期望窗口内。</li><li>根据顺序插入不同的队列：<ul><li>正常顺序 → 放入 <code>receive_queue</code> ；</li><li>超前包（乱序）→ 放入 <code>out_of_order_queue</code> 。</li></ul></li><li>当缺失的包到达后，触发 reordering，把 <code>out_of_order</code> 中的连续数据搬到
<code>receive_queue</code> 。</li><li>用户进程调用 <code>recv()</code> ：<ul><li>如果数据已在 <code>receive_queue</code> → 直接拷贝到用户缓冲区；</li><li>如果没有数据 → 阻塞等待或立即返回（非阻塞）。</li></ul></li></ol><h3 id=二-四个队列的作用与位置>二、四个队列的作用与位置</h3><h4 id=backlog-队列>1️⃣ backlog 队列</h4><ul><li><strong>作用</strong> ：保存还未被应用层 <code>accept()</code> 的连接。</li><li><strong>位置</strong> ：属于 <code>listen socket</code> ，即服务器监听套接字。</li><li><strong>说明</strong> ：<ul><li>TCP 三次握手完成后，内核把新连接放入 backlog 队列；</li><li>应用层调用 <code>accept()</code> 时，从 backlog 取出一个连接生成新的
<code>established socket</code> ；</li><li>一旦生成，接下来的数据接收就交给该新 socket
的接收队列体系（即下面几个队列）。</li></ul></li></ul><blockquote><p>所以 backlog 队列不存放数据包，只存放“还未被 accept 的连接请求”。</p></blockquote><hr><h4 id=prequeue-队列>2️⃣ prequeue 队列</h4><ul><li><strong>作用</strong> ： <strong>优化阻塞接收的性能</strong> ，在用户进程被唤醒之前，先行收包。</li><li><strong>背景</strong> ：<ul><li>在老版本内核（&lt;3.x）中，如果用户进程正在 <code>recv()</code>
阻塞等待，新的数据包到达时，内核可以直接把数据放入 prequeue；</li><li>等用户进程被唤醒时，可以直接从 prequeue 拷贝，提高效率。</li></ul></li><li><strong>现在的情况</strong> ：<ul><li>prequeue 在现代内核中基本被废弃（替换为 <code>sk_receive_queue</code> 和
<code>sk_backlog</code> 的合并机制）；</li><li>但在理论模型中，它表示 <strong>&ldquo;阻塞时提前积累的数据&rdquo;</strong> 。</li></ul></li></ul><hr><h4 id=out_of_order-队列>3️⃣ out_of_order 队列</h4><ul><li><strong>作用</strong> ：缓存 <strong>乱序到达的 TCP 报文段</strong> 。</li><li><strong>典型场景</strong> ：<ul><li>已收到 S1-S2；</li><li>缺少 S2-S3；</li><li>但先收到了 S3-S4；</li><li>那么 S3-S4 会被放到 <code>out_of_order queue</code> 。</li></ul></li><li><strong>工作机制</strong> ：<ul><li>当丢失的包（S2-S3）到达后，内核检测到连续性被恢复；</li><li>会遍历 out_of_order 队列，将连续的数据段合并并移动到
<code>receive queue</code> 。</li></ul></li></ul><hr><h4 id=receive-队列>4️⃣ receive 队列</h4><ul><li><strong>作用</strong> ：缓存 <strong>按序排列好的数据段</strong> ，等待用户进程读取。</li><li><strong>结构</strong> ：<ul><li>是 TCP socket 的核心接收缓存（ <code>sk_receive_queue</code> ）；</li><li>存放的都是 <strong>完整、有序的 TCP 数据段</strong> ；</li><li>用户调用 <code>recv()</code> / <code>read()</code> 时从这里复制数据到用户空间。</li></ul></li><li><strong>特点</strong> ：<ul><li>内核在接收时优先写入 <code>receive_queue</code> ；</li><li>如果数据还不完整（有缺失序号），暂时放入 <code>out_of_order_queue</code> 。</li></ul></li></ul><hr><h3 id=三-详细步骤解析-对应图中序号>三、详细步骤解析（对应图中序号）</h3><p>以下对应图中编号逐步解释：</p><table><thead><tr><th>步骤</th><th>内容</th><th>队列变化</th></tr></thead><tbody><tr><td>1</td><td>收到按序包 S1-S2 → 插入 <code>receive_queue</code></td><td>✅ receive</td></tr><tr><td>2</td><td>收到乱序包 S3-S4 → 插入 <code>out_of_order_queue</code></td><td>✅ out_of_order</td></tr><tr><td>3</td><td>后续补上 S2-S3 → 插入 <code>receive_queue</code></td><td>✅ receive</td></tr><tr><td>4</td><td>遍历 <code>out_of_order</code> ，发现可以衔接 → S3-S4 搬入 <code>receive_queue</code></td><td><code>out_of_order</code> 为空</td></tr><tr><td>5</td><td>应用层调用 <code>recv()</code> → 阻塞等待或直接读取</td><td>取数据</td></tr><tr><td>6</td><td>内核执行 <code>tcp_recvmsg()</code> → 锁定 socket</td><td>内核收包路径</td></tr><tr><td>7</td><td>从 <code>receive_queue</code> 取按序报文</td><td>数据取出</td></tr><tr><td>8-10</td><td>拷贝到用户缓冲区</td><td>数据用户可见</td></tr><tr><td>11</td><td>返回 recv()</td><td></td></tr><tr><td>12</td><td>判断是否达到低水位（ <code>SO_RCVLOWAT</code> ）</td><td>控制阻塞唤醒时机</td></tr><tr><td>13</td><td>recv() 返回已拷贝字节数</td><td>完成</td></tr></tbody></table><hr><h3 id=四-阻塞与非阻塞场景对比>四、阻塞与非阻塞场景对比</h3><h4 id=阻塞模式-默认>阻塞模式（默认）</h4><ol><li>用户调用 <code>recv()</code> 时如果 <code>receive_queue</code> 为空：<ul><li>进程进入休眠（TASK_INTERRUPTIBLE）；</li><li>内核挂起等待数据到达；</li></ul></li><li>数据到达后：<ul><li>进入 <code>receive_queue</code> ；</li><li>唤醒阻塞的进程；</li><li>拷贝数据到用户缓冲区；</li><li>返回实际读取的字节数。</li></ul></li></ol><p><strong>特点：</strong></p><ul><li>高效（内核等待，不忙轮询）；</li><li>延迟较小；</li><li>适合普通网络服务（如 HTTP、RPC 等）。</li></ul><hr><h4 id=非阻塞模式-o-nonblock>非阻塞模式（ <code>O_NONBLOCK</code> ）</h4><ol><li><p>用户调用 <code>recv()</code> ；</p></li><li><p>如果 <code>receive_queue</code> 为空，立即返回 <code>EAGAIN</code> ；</p></li><li><p>程序一般会配合 <code>select()</code> / <code>epoll()</code> 等机制等待可读事件；</p></li><li><p>一旦可读事件触发（有数据进入 <code>receive_queue</code> ），再次调用 <code>recv()</code> 读取。</p><p><strong>特点：</strong></p></li><li><p>不阻塞用户线程；</p></li><li><p>适合高并发、多连接场景；</p></li><li><p>常用于事件驱动模型（如 Nginx、Netty）。</p></li></ol><hr><h3 id=五-内核中主要结构对应关系>五、内核中主要结构对应关系</h3><table><thead><tr><th>队列名称</th><th>内核结构字段</th><th>功能说明</th></tr></thead><tbody><tr><td>backlog</td><td><code>sk_backlog</code></td><td>存放尚未处理的连接或收包</td></tr><tr><td>prequeue</td><td><code>sk_prequeue</code></td><td>（旧机制）阻塞时提前积累数据</td></tr><tr><td>receive queue</td><td><code>sk_receive_queue</code></td><td>已按序数据，等待用户读取</td></tr><tr><td>out_of_order queue</td><td><code>tcp_out_of_order_queue</code></td><td>保存乱序数据</td></tr></tbody></table><hr><h3 id=六-总结类比>六、总结类比</h3><p>可以把 TCP 的这些队列想象成邮局分拣过程：</p><table><thead><tr><th>阶段</th><th>类比</th></tr></thead><tbody><tr><td>backlog</td><td>邮局门口堆放未登记的包裹（新连接）</td></tr><tr><td>prequeue</td><td>快递员暂时帮忙堆放、准备的包裹</td></tr><tr><td>out_of_order</td><td>邮件分拣中心放错架的包裹（乱序）</td></tr><tr><td>receive queue</td><td>收件柜中按顺序排列等待取件的包裹</td></tr><tr><td>recv()</td><td>用户来取件（读取）</td></tr></tbody></table><hr><h2 id=一-总体流程>一、总体流程</h2><figure><img src=/images/tcp-revv-flow-process.png></figure><p><a href="https://people.redhat.com/pladd/MHVLUG_2017-04_Network_Receive_Stack.pdf?utm_source=chatgpt.com">people.redhat.com+1</a></p><hr><h2 id=二-按阶段详解>二、按阶段详解</h2><h3 id=a-dot-网卡-softirq-napi>A. 网卡 → softirq / NAPI</h3><p>网卡驱动在中断或 NAPI poll 中把数据封装成 <code>struct sk_buff skb</code> ，并提交上层：</p><ul><li>NIC 把数据 DMA 到环形缓冲区，触发 IRQ（或使用 NAPI 使能轮询）。驱动在
NAPI 的 <code>poll()</code> 中拿到 <code>skb</code> 并交给内核上层： <code>netif_receive_skb()</code>
内核通过softirq (<code>net_rx_action</code>) 处理接收链路。
<strong>并不触及 socket 的 receive/out_of_order socket 这些队列</strong> ，<a href="https://people.redhat.com/pladd/MHVLUG_2017-04_Network_Receive_Stack.pdf?utm_source=chatgpt.com">people.redhat.com+1</a></li></ul><hr><h3 id=b-dot-ip-层-ipv4-ipv6>B. IP 层（IPv4/IPv6）</h3><ul><li><code>netif_receive_skb()</code> → IP 层分发： <code>ip_rcv()</code> / <code>ip_local_deliver()</code> →
如果目标本机且是 TCP，则交给 TCP 的 net_protocol： <code>tcp_v4_rcv()</code> （IPv6
类似 <code>tcp_v6_rcv()</code> ）。这里会做报头检查、路由判定、Netfilter hook 等。<a href="https://medium.com/%40dipakkrdas/netfilter-and-iptables-f8a946bb83af?utm_source=chatgpt.com">Medium+1</a></li></ul><hr><h3 id=c-dot-tcp-层-socket-查找-and-状态处理>C. TCP 层：socket 查找 & 状态处理</h3><ul><li><p><code>tcp_v4_rcv()</code> 会查找目标 socket（ <code>__inet_lookup()</code> / 相关哈希表），
若找到对应 <code>struct sock *sk</code> ，进入tcp_v4_do_rcv()=（或直接 <code>tcp_v4_do_rcv()</code> 被调用的路径）。
如果 socket 是监听状态，会转到连接请求处理（ <code>tcp_v4_conn_request()</code> / backlog 相关）。<a href="https://codebrowser.dev/linux/linux/net/ipv4/tcp_ipv4.c.html?utm_source=chatgpt.com">codebrowser.dev+1</a></p></li><li><p><strong>与 <code>backlog</code> 的关系</strong> ：</p><ul><li>新连接（SYN→SYN-ACK→ACK 完成三次握手或带 cookie 的情况）会先放到监听 socket 的 <strong>backlog / accept queue</strong> ，
等待应用 <code>accept()</code> 。backlog 是“尚未 accept 的连接队列”，它 <strong>不保存数据包</strong> ，
而保存 <code>struct inet_connection_sock</code> / <code>request_sock</code> 的新连接对象。<a href="https://people.computing.clemson.edu/~westall/853/notes/tcprecv.pdf?utm_source=chatgpt.com">people.computing.clemson.edu</a></li></ul></li></ul><hr><h3 id=d-dot-数据入队-tcp-rcv-established-tcp-data-queue-关键>D. 数据入队： <code>tcp_rcv_established()</code> / <code>tcp_data_queue()</code> （关键）</h3><h4 id=在已建立连接-established-时-数据处理主路径通常是>在已建立连接（ESTABLISHED）时，数据处理主路径通常是：</h4><figure><img src=/images/tcp_data_handle_path.png></figure><ul><li><code>tcp_rcv_established()</code>
对报文做序号/ACK/窗口检查，
然后调用排队逻辑（在 <code>net/ipv4/tcp_input.c</code> / <code>net/ipv4/tcp.c</code> 的相关函数）。<a href="https://codebrowser.dev/linux/linux/net/ipv4/tcp_input.c.html?utm_source=chatgpt.com">codebrowser.dev+1</a></li></ul><h4 id=决定具体放哪个队列>决定具体放哪个队列：</h4><ol><li><code>tcp_v4_do_rcv()</code> 根据连接状态调用：<ul><li><code>tcp_rcv_established()</code> （连接已经建立的常见路径）</li><li>或 <code>tcp_rcv_state_process()</code> （处理其它状态的通用入口）。
这两处最终会调用
<code>tcp_data_queue()</code> （或者在特殊快路径直接处理）。<a href="https://wiki.linuxfoundation.org/networking/kernel_flow?utm_source=chatgpt.com">wiki.linuxfoundation.org+1</a></li></ul></li><li><code>tcp_data_queue()</code> 的职责：<ul><li><strong>顺序到达（in-order, 无特殊标志）</strong> ：走快路径，直接把数据追加到 socket
的接收队列（ <code>sk_receive_queue</code> ，也就是图里的 <code>receive</code> 队列），并执行一些 ACK / 拥塞相关处理；</li><li><strong>乱序包</strong> ：如果包的序号超前（缺失之前的段），调用 <code>tcp_ofo_queue()</code>
或相关逻辑把 <code>skb</code> 放入 <strong>connection-level 的 out_of_order=（ofo）队列</strong> 。
当缺失的中间段到达并能拼接时，内核会把 <code>out_of_order</code> 中连续段移动到 <code>receive</code> 队列。<a href="https://datatag.web.cern.ch/papers/tr-datatag-2004-1.pdf?utm_source=chatgpt.com">datatag.web.cern.ch+1</a></li></ul></li><li><strong>prequeue</strong> ：<ul><li>这是内核中曾存在的“快速路径优化”
概念：当用户进程处于阻塞等待时，内核先把到达的数据先放到一个
<code>prequeue</code>
以便唤醒后直接拷贝（或加速传输）。现代5.x内核把相关优化融合进
<code>sk_receive_queue</code> / <code>sk_backlog</code> 的处理，但概念上 <code>prequeue</code>
表示“在用户唤醒前预先聚集的数据”。因此你在源码里较少能见到独立名为
<code>prequeue</code> 的广泛使用结构，但逻辑上的“预拷贝/预排队”仍然存在。（文献与历史实现有所差异）<a href="https://people.redhat.com/pladd/MHVLUG_2017-04_Network_Receive_Stack.pdf?utm_source=chatgpt.com">people.redhat.com+1</a></li></ul></li><li><strong>backlog</strong> ：<ul><li>注意 <code>backlog</code> 在语义上是 <strong>与 accept/连接队列相关</strong> 的：当监听
socket（ <code>listen()</code> ）时，完成三次握手的新连接被放入 <code>backlog</code> （或 accept 队列），
等待用户 <code>accept()=。=backlog</code> 不是用来放数据包的（数据包进来是针对已存在的已 <code>accept()</code> 的 socket
才进 <code>receive</code> / <code>ofo</code> ）。<a href="https://people.redhat.com/pladd/MHVLUG_2017-04_Network_Receive_Stack.pdf?utm_source=chatgpt.com">people.redhat.com</a></li></ul></li></ol><blockquote><p>小结： <code>receive</code> （sk_receive_queue）存放按序并可被用户读取的数据； <code>out_of_order</code>
存放超前、暂时不能交付用户的段。</p></blockquote><hr><h3 id=e-dot-唤醒用户态-sk-data-ready-sock-queue-rcv-skb>E. 唤醒用户态（ <code>sk_data_ready</code> / <code>sock_queue_rcv_skb</code> ）</h3><ul><li>当数据成功入
<code>sk_receive_queue</code> （或在某些路径直接拷贝给等待的进程），
内核通过 <code>sock_queue_rcv_skb()</code> （或直接调用 <code>sk->sk_data_ready(sk, skb_len)</code> ）触发 <code>sk_data_ready</code> 回调，
最终走到 <code>sock_def_readable</code> / <code>wake_up_interruptible_sync_poll()</code> 来唤醒阻塞的 <code>recv()</code> 或产生 <code>EPOLLIN</code> 事件。<a href="https://stackoverflow.com/questions/14040328/callback-function-in-socket-as-sk-data-ready?utm_source=chatgpt.com">Stack Overflow+1</a><ul><li>对阻塞的 <code>recv()</code> 进程执行唤醒（唤醒后用户进程继续在 <code>tcp_recvmsg()</code> 中拷贝）；</li><li>对使用 epoll/poll 的程序，产生 <code>EPOLLIN</code> / POLLIN 事件。<a href="https://codebrowser.dev/linux/linux/net/ipv4/tcp.c.html?utm_source=chatgpt.com">codebrowser.dev</a></li></ul></li></ul><hr><h3 id=f-dot-用户态读取-tcp-recvmsg-recv-返回>F. 用户态读取： <code>tcp_recvmsg()</code> / <code>recv()</code> 返回</h3><ol><li>用户态调用 <code>recv()</code> → 内核调用 <code>sock_recvmsg()</code> →
<code>inet_recvmsg()</code> → <code>tcp_recvmsg()</code> （在 <code>net/ipv4/tcp.c</code> / <code>net/ipv4/tcp_impl.c</code> 中）。
<code>tcp_recvmsg()</code> 的职责：<ul><li>拿 socket 锁（ <code>lock_sock(sk)</code> ）；</li><li>检查 <code>sk_receive_queue</code> 是否有数据；<ul><li>如果有，就调用 <code>skb_copy_datagram_iter()</code> / <code>skb_copy_and_csum_datagram_iovec()</code>
等把数据拷贝到用户 <code>iovec</code> 中，更新队列（ <code>skb_pull()</code> / <code>skb_unlink()</code> 等），返回拷贝字节数；</li><li>如果没有且 socket 为阻塞模式，则设置进程为 <code>TASK_INTERRUPTIBLE</code>
并 <code>wait_event_*</code> 直到 <code>sk_data_ready</code> 唤醒；若为非阻塞则立即返回 <code>-EAGAIN</code> 。<a href="https://codebrowser.dev/linux/linux/net/ipv4/tcp.c.html?utm_source=chatgpt.com">codebrowser.dev+1</a></li></ul></li></ul></li><li><code>tcp_recvmsg()</code> 还负责维护 <code>SO_RCVLOWAT</code> / <code>sk->sk_receive_queue</code>
的低水位检测与更新（决定何时再次唤醒等），以及在拷贝后可能触发 <code>tcp_recv_window()</code> 的窗口更新逻辑。<a href="https://codebrowser.dev/linux/linux/net/ipv4/tcp.c.html?utm_source=chatgpt.com">codebrowser.dev</a></li></ol><hr><h3 id=完整调用链>完整调用链</h3><p>下面是从 skb 到用户 <code>recv()</code> 的关键函数（按执行顺序，5.15.0源码）：</p><ul><li>NIC/driver poll → <code>napi_gro_receive() / netif_receive_skb() 。</code> （网卡驱动/ net/core/dev.c）<a href="https://www.exploit-db.com/exploits/47163?utm_source=chatgpt.com">exploit-db.com</a></li><li>=ip_rcv() / ip_local_deliver() （IPv4，net/ipv4/ip_input.c）→
分发到：</li><li><code>tcp_v4_rcv()（net/ipv4/tcp_ipv4.c / net/ipv4/tcp_input.c</code> ）→
<code>tcp_v4_do_rcv()</code> 。<a href="https://codebrowser.dev/linux/linux/net/ipv4/tcp_ipv4.c.html?utm_source=chatgpt.com">codebrowser.dev+1</a></li><li><code>tcp_rcv_state_process()</code> / <code>tcp_rcv_established() （net/ipv4/tcp_input.c</code> ）→
验证序号/窗口/标志。<a href="https://codebrowser.dev/linux/linux/net/ipv4/tcp_input.c.html?utm_source=chatgpt.com">codebrowser.dev</a></li><li>排队： <code>tcp_data_queue()</code> / <code>tcp_queue_rcv()</code> （或直接 <code>tcp_ofo_queue()</code> ）将 skb 放入：<ul><li><code>sk_receive_queue</code> （in-order）或</li><li><code>tcp->out_of_order</code> （ofo，乱序缓存）。<a href="https://codebrowser.dev/linux/linux/net/ipv4/tcp_input.c.html?utm_source=chatgpt.com">codebrowser.dev</a></li></ul></li><li>当放入 <code>sk_receive_queue</code> 时调用 <code>sock_queue_rcv_skb()</code> 或直接调用
<code>sk->sk_data_ready</code> → 触发唤醒 / epoll 事件。<a href="https://codebrowser.dev/linux/linux/net/ipv4/tcp.c.html?utm_source=chatgpt.com">codebrowser.dev</a></li><li>用户读取： <code>sys_recvfrom</code> → <code>sock_recvmsg</code> → <code>inet_recvmsg</code> →
<code>tcp_recvmsg （net/ipv4/tcp.c / tcp_recvmsg</code> 实现）→ 从
<code>sk_receive_queue</code> 拷贝数据到用户空间，返回字节数。<a href="https://codebrowser.dev/linux/linux/net/ipv4/tcp.c.html?utm_source=chatgpt.com">codebrowser.dev+1</a></li></ul><h2 id=三-阻塞-vs-非阻塞-内核里的差别-流程上哪些点不一样>三、阻塞 vs 非阻塞：内核里的差别（流程上哪些点不一样）</h2><p>三阻塞-vs-非阻塞内核里的差别流程上哪些点不一样</p><h3 id=阻塞-socket-默认>阻塞 socket（默认）</h3><ul><li>如果 <code>recv()</code> 时, <code>sk_receive_queue</code> 为空，线程会睡眠（ <code>TASK_INTERRUPTIBLE</code> ），直到：<ul><li><code>sk_data_ready()</code> 被触发（有数据入队），或</li><li>收到信号 / 超时等。</li></ul></li><li>内核在 <code>tcp_data_queue()</code> 入队后会唤醒阻塞进程；部分路径会利用“预拷贝
/prequeue”减少唤醒后拷贝延迟。整体上更节能、延迟低（因为不会忙循环）。<a href="https://wiki.linuxfoundation.org/networking/kernel_flow?utm_source=chatgpt.com">wiki.linuxfoundation.org+1</a></li></ul><h3 id=非阻塞-socket-o-nonblock>非阻塞 socket（=O_NONBLOCK=）</h3><ul><li><code>recv()</code> 立即返回 <code>-EAGAIN</code> / <code>EWOULDBLOCK</code> （如果没有数据）。</li><li>用户程序通常通过 <code>select / poll/ epoll</code> 等等待可读事件；内核仍然在
<code>tcp_data_queue()</code> 把数据放入 <code>sk_receive_queue</code> 并触发 <code>EPOLLIN</code> （sk_data_ready），
但不会把线程阻塞在 <code>recv()</code> 上。<a href="https://stackoverflow.com/questions/14040328/callback-function-in-socket-as-sk-data-ready?utm_source=chatgpt.com">Stack Overflow</a></li></ul><p><strong>换句话说</strong> ：数据如何被内核接收与排队（ <code>receive</code> / <code>out_of_order</code> ）是相同的；
不同点是内核是否在 <code>recv()</code> 时直接把用户睡眠起来等待数据（阻塞）或让 <code>recv()</code>
立即返回（非阻塞）并通过事件通知唤醒/告知用户。</p><hr><h2 id=四-源码定位>四、源码定位</h2><ul><li>驱动 / napi / netif： <code>drivers/...</code> （各网卡驱动的 <code>poll()）→ net/core/dev.c</code> 中 <code>netif_receive_skb() / napi_gro_receive()</code> 等。<a href="https://people.redhat.com/pladd/MHVLUG_2017-04_Network_Receive_Stack.pdf?utm_source=chatgpt.com">people.redhat.com</a></li><li>IP 层： <code>net/ipv4/ip_input.c (ip_rcv / ip_local_deliver)、 net/ipv6/</code> 对应文件。<a href="https://medium.com/%40dipakkrdas/netfilter-and-iptables-f8a946bb83af?utm_source=chatgpt.com">Medium</a></li><li>TCP层（关键）：
<code>net/ipv4/tcp.c、net/ipv4/tcp_input.c、net/ipv4/tcp_ipv4.c</code> ：
看 <code>tcp_v4_rcv()、tcp_v4_do_rcv()、tcp_rcv_established()、tcp_data_queue()、 tcp_ofo_queue()、tcp_queue_rcv()、tcp_recvmsg()</code> 等。<a href="https://codebrowser.dev/linux/linux/net/ipv4/tcp.c.html?utm_source=chatgpt.com">codebrowser.dev+1</a></li><li>socket 层/队列操作：
<code>net/core/sock.c （如sock_queue_rcv_skb()、sk->sk_data_ready</code> 调用链）。<a href="https://docs.kernel.org/networking/kapi.html?utm_source=chatgpt.com">docs.kernel.org</a></li></ul><h2 id=五-补充说明>五、补充说明</h2><ul><li><strong>backlog ≠ receive</strong> ： <code>backlog</code> 属于监听 socket 的连接队列（accept），不是数据缓冲队列。只有连接被 <code>accept()</code> 后，新的
<code>established</code> socket 才有 <code>sk_receive_queue /ofo</code> 。<a href="https://people.computing.clemson.edu/~westall/853/notes/tcprecv.pdf?utm_source=chatgpt.com">people.computing.clemson.edu</a></li><li><strong>ofo 的清理时机</strong> ：当缺失段到达或超时重传（触发重传/ACK 机制）后，
内核会检查 <code>ofo</code> ，将可连续拼接的段搬到 <code>sk_receive_queue</code> 。<a href="https://codebrowser.dev/linux/linux/net/ipv4/tcp_input.c.html?utm_source=chatgpt.com">codebrowser.dev</a></li><li><strong>prequeue 是优化不是必然存在的独立结构</strong> ：在 5.x 源码里很多“预拷贝/快速唤醒”逻辑会出现在
<code>sock_queue_rcv_skb()、tcp_try_coalesce()、skb_queue_*</code> 的
fastpath 中，而不是单独的 <code>prequeue</code> 名称。</li></ul><h2 id=六-关于原文-高性能网络编程3-tcp消息的接收-的进一步理解>六、关于原文 <a href=https://www.taohui.pub/2016/01/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B3-tcp%E6%B6%88%E6%81%AF%E7%9A%84%E6%8E%A5%E6%94%B6/>高性能网络编程3-tcp消息的接收</a> 的进一步理解</h2><h3 id=原文描述如下>原文描述如下：</h3><p>上图中有 13个步骤，应用进程使用了阻塞套接字，调用 recv 等方法时 flag 标志位为
0，用户进程读取套接字时没有发生进程睡眠。内核在处理接收到的 TCP
报文时使用了 4 个队列容器（当链表理解也可），分别为
receive、out_of_order、prequeue、backlog 队列，本文会说明它们存在的意义。下面详细说明这 13 个步骤。</p><p>1、当网卡接收到报文并判断为 TCP
协议后，将会调用到内核的tcp_v4_rcv方法。此时，这个 TCP
连接上需要接收的下一个报文序号恰好就是
S1，而这一步里，网卡上收到了S1-S2的报文，所以，tcp_v4_rcv方法会把这个报文直接插入到receive队列中。</p><p>注意：receive 队列是允许用户进程直接读取的，它是将已经接收到的 TCP
报文，去除了 TCP
头部、排好序放入的、用户进程可以直接按序读取的队列。由于 socket
不在进程上下文中（也就是没有进程在读 socket），由于我们需要 S1
序号的报文，而恰好收到了S1-S2报文，因此，它进入了 receive 队列。</p><p>2、接着，我们收到了S3-S4报文。在第 1 步结束后，这时我们需要收到的是 S2
序号，但到来的报文却是 S3
打头的，怎么办呢？进入out_of_order队列！从这个队列名称就可以看出来，所有乱序的报文都会暂时放在这。</p><p>3、仍然没有进入来读取 socket，但又过来了我们期望的S2-S3报文，它会像第 1
步一样，直接进入 receive
队列。不同的时，由于此时out_of_order队列不像第1步是空的，所以，引发了接来的第
4 步。</p><p>4、每次向receive队列插入报文时都会检查out_of_order队列。由于收到S2-S3报文后，期待的序号成为了
S3，这样，out_of_order队列里的唯一报文S3-S4报文将会移出本队列而插入到receive队列中（这件事由tcp_ofo_queue方法完成）。</p><p>5、终于有用户进程开始读取 socket
了。做过应用端编程的同学都知道，先要在进程里分配一块内存，接着调用 read
或者 recv 等方法，把内存的首地址和内存长度传入，再把建立好连接的 socket
也传入。当然，对这个 socket
还可以配置其属性。这里，假定没有设置任何属性，都使用默认值，因此，此时
socket 是阻塞式，它的SO_RCVLOWAT是默认的1。当然，recv
这样的方法还会接收一个 flag
参数，它可以设置为MSG_WAITALL、MSG_PEEK、MSG_TRUNK等等，这里我们假定为最常用的
0。进程调用了 recv 方法。</p><p>6、无论是何种接口，C
库和内核经过层层封装，接收TCP消息最终一定会走到tcp_recvmsg方法。下面介绍代码细节时，它会是重点。</p><p>7、在tcp_recvmsg方法里，会首先锁住 socket。为什么呢？因此 socket
是可以被多进程同时使用的，同时，内核中断也会操作它，而下面的代码都是核心的、操作数据的、有状态的代码，不可以被重入的，锁住后，再有用户进程进来时拿不到锁就要休眠在这了。内核中断看到被锁住后也会做不同的处理，参见图
2、图 3。</p><p>8、此时，第 1-4 步已经为 receive 队列里准备好了 3
个报文。最上面的报文是S1-S2，将它拷贝到用户态内存中。由于第 5
步flag参数并没有携带MSG_PEEK这样的标志位，因此，再将S1-S2报文从receive队列的头部移除，从内核态释放掉。反之，MSG_PEEK标志位会导致receive队列不会删除报文。所以，MSG_PEEK主要用于多进程读取同一套接字的情形。</p><p>9、如第 8
步，拷贝S2-S3报文到用户态内存中。当然，执行拷贝前都会检查用户态内存的剩余空间是否足以放下当前这个报文，不足以时会直接返回已经拷贝的字节数。</p><p>10、同上。</p><p>11、receive
队列为空了，此时会先来检查SO_RCVLOWAT这个阀值。如果已经拷贝的字节数到现在还小于它，那么可能导致进程会休眠，等待拷贝更多的数据。第
5 步已经说明过了，socket套接字使用的默认的SO_RCVLOWAT，也就是
1，这表明，只要读取到报文了，就认为可以返回了。</p><p>做完这个检查了，再检查 backlog 队列。backlog
队列是进程正在拷贝数据时，网卡收到的报文会进这个队列。此时若 backlog
队列有数据，就顺带处理下。图 3 会覆盖这种场景。</p><p>12、在本图对应的场景中，backlog
队列是没有数据的，已经拷贝的字节数为S4-S1，它是大于 1 的，因此，释放第 7
步里加的锁，准备返回用户态了。</p><p>13、用户进程代码开始执行，此时recv等方法返回的就是S4-S1，即从内核拷贝的字节数。</p><p>图1 描述的场景是最简单的1种场景，下面我们来看看上述步骤是怎样通过内核代码实现的（以下代码为2.6.18内核代码）。</p><p>我们知道，linux对中断的处理是分为上半部和下半部的，这是处于系统整体效率的考虑。我们将要介绍的都是在网络软中断的下半部里，例如这个tcp_v4_rcv方法。图1 中的第 1-4 步都是在这个方法里完成的。
这些表述与你提供的理解有出入，尤其是 backlog部分，原作者提到的是可以存放网卡传过来的报文</p><h3 id=一-tcp-报文接收的完整路径-总体流程>一、TCP 报文接收的完整路径（总体流程）</h3><p>TCP 报文的接收大致分为两类上下文：</p><ol><li><strong>软中断（net_rx softirq）上下文</strong> &mdash;&mdash; 处理网卡收到的数据包；</li><li><strong>进程上下文（用户调用 recv 等函数）</strong> &mdash;&mdash; 应用程序取出数据。</li></ol><p>两者之间的核心“桥梁”就是内核维护的几个 TCP 接收队列。</p><hr><h3 id=二-四个关键队列的角色-5-dot-15-内核视角>二、四个关键队列的角色（5.15 内核视角）</h3><table><thead><tr><th>队列名</th><th>所在位置</th><th>作用</th><th>典型触发时机</th></tr></thead><tbody><tr><td><strong>receive_queue</strong></td><td><code>struct tcp_sock::receive_queue</code></td><td>已经按序、可被用户进程直接读取的数据段（payload）</td><td>收到预期的下一个序号（in-order 报文）时放入</td></tr><tr><td><strong>out_of_order_queue (ofo_queue)</strong></td><td><code>struct tcp_sock::out_of_order_queue</code></td><td>缓存乱序到达的数据段（out-of-order segments）</td><td>收到大于预期序号的报文</td></tr><tr><td><strong>prequeue</strong></td><td><code>struct tcp_sock::prequeue</code></td><td>早期内核用来*加速进程阻塞在 recv()* 时的接收性能（5.15 中几乎废弃）</td><td>在 2.6&ndash;3.x 内核中有效；5.x 内核中仅残留结构</td></tr><tr><td><strong>backlog</strong></td><td><code>struct sock::sk_backlog</code></td><td>当 socket 被锁定或进程在处理数据时，新到的报文会暂存在此</td><td>socket 被加锁或正在 <code>tcp_recvmsg()</code> 中复制数据时收到新的包</td></tr></tbody></table><hr><h3 id=三-结合图中-13-个步骤的逐步解释-以-5-dot-15-内核为参考>三、结合图中 13 个步骤的逐步解释（以 5.15 内核为参考）</h3><h4 id=步骤-1-4-软中断路径-tcp-v4-rcv>步骤 1&ndash;4：软中断路径（tcp_v4_rcv）</h4><p>1️⃣ <strong>S1-S2 报文到达：</strong></p><ul><li>当前 TCP 期望 <code>rcv_nxt = S1</code> 。</li><li>报文正好匹配期望序号 → 调用 <code>tcp_queue_rcv()</code> → 插入 <strong>receive_queue</strong> 。</li><li>因为是 in-order，可立即被用户读取。</li></ul><p>2️⃣ <strong>S3-S4 报文到达（乱序）：</strong></p><ul><li>期望序号为 S2，而收到 S3 → 插入 <strong>out_of_order_queue</strong> 。</li><li>不进入 receive_queue，等待缺失的 S2。</li></ul><p>3️⃣ <strong>S2-S3 报文到达：</strong></p><ul><li>期望序号为 S2 → 插入 receive_queue；</li><li>插入完成后触发 =tcp_ofo_queue()=，发现 out_of_order 队列中 S3-S4
连续，取出并合并；</li><li>此时 receive_queue 连续为 S1-S2-S3-S4。</li></ul><p>4️⃣ <strong>out_of_order -> receive 的合并：</strong></p><ul><li><code>tcp_try_coalesce()、tcp_ofo_queue()</code> 完成拼接；</li><li>receive_queue 现在已经完整有序。</li></ul><hr><h4 id=步骤-5-7-应用层阻塞调用-recv>步骤 5&ndash;7：应用层阻塞调用 recv()*</h4><p>5️⃣ 应用调用 <code>recv()</code> ：</p><ul><li>flag = 0（阻塞），SO_RCVLOWAT = 1；</li><li>进入 <code>tcp_recvmsg()</code> ；</li><li>锁住 socket → 防止中断同时修改队列。</li></ul><p>6️⃣ 如果 receive_queue 为空：</p><ul><li>阻塞在 <code>sk_wait_data()</code> ；</li><li>等待软中断填入 receive_queue 或 backlog；</li><li>如果是非阻塞 socket（O_NONBLOCK），此时立即返回 <code>EAGAIN</code> 。</li></ul><p>7️⃣ 如果有数据（此处已准备好 S1&ndash;S4）：</p><ul><li>从 receive_queue 头开始拷贝；</li><li>调用 <code>skb_copy_datagram_msg()</code> 将内核 skb 数据拷贝到用户缓冲。</li></ul><hr><h4 id=步骤-8-10-数据拷贝到用户空间>步骤 8&ndash;10：数据拷贝到用户空间</h4><p>8-10 每次拷贝完一个 SKB：</p><ul><li>若 flag 未设置 MSG_PEEK → 删除 skb；</li><li>若 buffer 空间不足 → 返回已拷贝字节数；</li><li>如果拷贝后 receive_queue 为空 → 检查 backlog。</li></ul><hr><h4 id=步骤-11-12-backlog-检查与返回>步骤 11&ndash;12：backlog 检查与返回</h4><ol><li><p>当 recv() 仍持有 socket 锁时：</p></li><li><p>若 backlog 队列中有新到的 skb（中断期间存入），则取出并放入 receive_queue；</p></li><li><p>这样应用一次 recv() 可直接读到 backlog 队列积压的数据。</p></li><li><p>若 receive_queue 和 backlog 都为空：</p></li><li><p>检查 SO_RCVLOWAT；</p></li><li><p>已读字节 >= 阈值 → 返回；</p></li><li><p>否则继续睡眠（阻塞模式）或返回 EAGAIN（非阻塞模式）。</p></li><li><p>最终返回到用户态：</p></li><li><p>返回字节数 = S4 &ndash; S1；</p></li><li><p>应用获得连续的 TCP 流数据。</p></li></ol><hr><h3 id=四-四个队列之间的交互总结图>四、四个队列之间的交互总结图</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>网卡中断 → tcp_v4_rcv
</span></span><span style=display:flex><span>        │
</span></span><span style=display:flex><span>        ├─ in-order → receive_queue
</span></span><span style=display:flex><span>        ├─ out-of-order → out_of_order_queue
</span></span><span style=display:flex><span>        ├─ socket locked → backlog (延迟处理)
</span></span><span style=display:flex><span>        └─ （旧内核）用户阻塞 recv → prequeue (已废弃)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>应用进程 recv()
</span></span><span style=display:flex><span>        │
</span></span><span style=display:flex><span>        ├─ 优先读 receive_queue
</span></span><span style=display:flex><span>        ├─ 再处理 backlog
</span></span><span style=display:flex><span>        └─ 若为空：阻塞或 EAGAIN
</span></span></code></pre></div><hr><h3 id=五-阻塞-vs-非阻塞-recv-的差异>五、阻塞 vs 非阻塞 recv 的差异</h3><table><thead><tr><th>模式</th><th>关键行为</th><th>内核表现</th></tr></thead><tbody><tr><td><strong>阻塞 recv()</strong></td><td>若 receive_queue 空，进程挂起，直到新数据到达或超时</td><td>内核在 <code>sk_wait_data()</code> 等待唤醒，中断处理函数会唤醒进程</td></tr><tr><td><strong>非阻塞 recv() (O_NONBLOCK)</strong></td><td>若 receive_queue 空，立即返回 EAGAIN</td><td>不会进入睡眠；backlog 中数据也需下次调用时再处理</td></tr></tbody></table><hr><h3 id=六-prequeue-的现状-linux-5-dot-15>六、prequeue 的现状（Linux 5.15）</h3><ul><li>在 2.6 内核时期， <strong>prequeue</strong> 用于优化“进程阻塞等待数据”场景： 当用户在
<code>recv()</code> 中睡眠时，软中断直接把数据放进 prequeue，以便唤醒后可立即处理。</li><li>但随着 RFS（Receive Flow Steering）、NAPI 优化引入后，该机制在 <strong>3.x 后逐渐废弃</strong> 。</li><li>在 <strong>5.15</strong> 代码中仍保留结构体字段，但逻辑几乎已被移除或恒为空。</li></ul><hr><h3 id=七-总结>七、总结</h3><table><thead><tr><th>阶段</th><th>内核上下文</th><th>队列变化</th><th>用户层状态</th></tr></thead><tbody><tr><td>1&ndash;4</td><td>网络软中断</td><td>数据进入 receive 或 out_of_order；必要时从 ofo 移回 receive</td><td>用户进程未读</td></tr><tr><td>5&ndash;7</td><td>用户态调用 recv() → 进入内核</td><td>锁 socket，尝试读 receive；若空则阻塞或返回</td><td>阻塞或立即返回</td></tr><tr><td>8&ndash;10</td><td>内核到用户拷贝</td><td>从 receive 拷贝出、释放 SKB</td><td>用户获得数据</td></tr><tr><td>11&ndash;12</td><td>backlog 检查</td><td>backlog 数据迁移到 receive</td><td>若无数据则继续阻塞</td></tr><tr><td>13</td><td>返回用户态</td><td>返回字节数</td><td>完成一次读取</td></tr></tbody></table><hr><h3 id=简明描述13个步骤>简明描述13个步骤：</h3><p>1、内核收到报文S1-S2，S1 正是这个 socket
连接上待接收的序号，因此，直接将它插入有序的 receive 队列中。</p><p>2、用户进程所处的 linux
操作系统上，将sysctl中的tcp_low_latency设置为1。这意味着，这台服务器希望
TCP 进程能够更及时的接收到 TCP 消息。用户调用了 recv 方法接收 socket
上的消息，这个socket上设置了SO_RCVLOWAT属性为某个值n，这个n是大于S2-S1，也就是第
1 步收到的报文大小。这里，仍然是阻塞 socket，用户依然是分配了足够大的
len 长度内存以接收 TCP 消息。</p><p>3、通过tcp_recvmsg方法来完成接收工作。先锁住
socket，避免并发进程读取同一 socket
的同时，也在告诉内核网络软中断处理到这一 socket 时要有不同行为，如第 6
步。</p><p>4、准备处理内核各个接收队列中的报文。</p><p>5、receive
队列中的有序报文可直接拷贝，在检查到S2-S1是小于len之后，将报文内容拷贝到用户态内存中。</p><p>6、在第 5 步进行的同时，socket
是被锁住的，这时内核又收到了一个S3-S4报文，因此报文直接进入 backlog
队列。注意，这个报文不是有序的，因为此时连接上期待接收序号为 S2。</p><p>7、在第 5
步，拷贝了S2-S1个字节到用户内存，它是小于SO_RCVLOWAT的，因此，由于
socket
是阻塞型套接字（超时时间在本文中忽略），进程将不得不转入睡眠。转入睡眠之前，还会干一件事，就是处理
backlog 队列里的报文，图 2 的第 4
步介绍过休眠方法sk_wait_data，它在睡眠前会执行release_sock方法，看看是如何实现的：</p><p>void fastcall release_sock(struct sock *sk) {
mutex_release(&amp;sk->sk_lock.dep_map, 1, <em>RET_IP</em>);</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>spin_lock_bh(&amp;sk-&gt;sk_lock.slock);
</span></span><span style=display:flex><span>    //这里会遍历 backlog 队列中的每一个报文
</span></span><span style=display:flex><span>if (sk-&gt;sk_backlog.tail)
</span></span><span style=display:flex><span>    __release_sock(sk);
</span></span><span style=display:flex><span>    //这里是网络中断执行时，告诉内核，现在 socket 并不在进程上下文中
</span></span><span style=display:flex><span>sk-&gt;sk_lock.owner = NULL;
</span></span><span style=display:flex><span>if (waitqueue_active(&amp;sk-&gt;sk_lock.wq))
</span></span><span style=display:flex><span>    wake_up(&amp;sk-&gt;sk_lock.wq);
</span></span><span style=display:flex><span>spin_unlock_bh(&amp;sk-&gt;sk_lock.slock);
</span></span></code></pre></div><p>} 再看看__release_sock方法是如何遍历backlog队列的：</p><p>static void __release_sock(struct sock /sk) { struct sk_buff /skb =
sk->sk_backlog.head;</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>    //遍历 backlog 队列
</span></span><span style=display:flex><span>do {
</span></span><span style=display:flex><span>    sk-&gt;sk_backlog.head = sk-&gt;sk_backlog.tail = NULL;
</span></span><span style=display:flex><span>    bh_unlock_sock(sk);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    do {
</span></span><span style=display:flex><span>        struct sk_buff *next = skb-&gt;next;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        skb-&gt;next = NULL;
</span></span><span style=display:flex><span>                    //处理报文，其实就是tcp_v4_do_rcv方法，上文介绍过，不再赘述
</span></span><span style=display:flex><span>        sk-&gt;sk_backlog_rcv(sk, skb);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        cond_resched_softirq();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        skb = next;
</span></span><span style=display:flex><span>    } while (skb != NULL);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    bh_lock_sock(sk);
</span></span><span style=display:flex><span>} while((skb = sk-&gt;sk_backlog.head) != NULL);
</span></span></code></pre></div><p>}
此时遍历到S3-S4报文，但因为它是失序的，所以从backlog队列中移入out_of_order队列中（参见上文说过的tcp_ofo_queue方法）。</p><p>8、进程休眠，直到超时或者 receive 队列不为空。</p><p>9、内核接收到了S2-S3报文。注意，这里由于打开了tcp_low_latency标志位，这个报文是不会进入
prequeue 队列以待进程上下文处理的。</p><p>10、此时，由于 S2
是连接上正要接收的序号，同时，有一个用户进程正在休眠等待接收数据中，且它要等待的数据起始序号正是
S2，于是，这种种条件下，使得这一步同时也是网络软中断执行上下文中，把S2-S3报文直接拷贝进用户内存。</p><p>11、上文介绍tcp_data_queue方法时大家可以看到，每处理完 1
个有序报文（无论是拷贝到 receive
队列还是直接复制到用户内存）后都会检查out_of_order队列，看看是否有报文可以处理。那么，S3-S4报文恰好是待处理的，于是拷贝进用户内存。然后唤醒用户进程。</p><p>12、用户进程被唤醒了，当然唤醒后会先来拿到 socket
锁。以下执行又在进程上下文中了。</p><p>13、此时会检查已拷贝的字节数是否大于SO_RCVLOWAT，以及 backlog
队列是否为空。两者皆满足，准备返回。</p><p>14、释放 socket 锁，退出tcp_recvmsg方法。</p><p>15、返回用户已经复制的字节数S4-S1。 能通俗易懂的解释一下上述 tcp
接收报文的另一类流程吗？</p><h3 id=背景区别>背景区别</h3><ul><li><strong>当前图的场景</strong> ：<ul><li><code>tcp_low_latency = 1</code></li><li>表示“低延迟优先”，内核尽量让报文 <strong>直接唤醒用户进程并拷贝</strong> ，不进入预队列。</li><li>强调 <strong>实时响应</strong> （适合 RPC、在线请求类应用）。</li></ul></li><li><strong>另一类流程</strong> （对比场景: 非低延迟模式 + 正常阻塞接收 ）：<ul><li><code>tcp_low_latency = 0</code> （默认值）</li><li>表示“吞吐优先”，内核尽量 <strong>推迟唤醒用户进程</strong> ，把收到的报文 <strong>暂存在prequeue 队列中</strong> 。</li><li>等到用户进程下一次调用 <code>recv</code> 或系统有空时，再批量处理。</li><li>适合 <strong>大流量、高并发传输场景</strong> （比如文件下载、流媒体）。</li></ul></li></ul><hr><h3 id=简化理解的流程-tcp-low-latency-0>简化理解的流程（tcp_low_latency = 0）</h3><p>假设客户端发送了连续报文 <code>S1-S2, S2-S3, S3-S4</code> ，应用是阻塞 <code>recv</code> 。</p><hr><h4 id=1️⃣-报文到达-s1-s2>1️⃣ 报文到达（S1-S2）</h4><ul><li>网卡收到 TCP 段 → 内核协议栈解析。</li><li>内核发现该连接对应的 socket 正在 <strong>用户态 recv 调用中</strong> 。</li><li>因为 <strong>tcp_low_latency=0</strong> ，内核不会立刻唤醒用户进程。</li><li>报文被放入 <strong>prequeue 队列（预处理队列）</strong> 。</li><li>此时用户态还在等待数据，没被唤醒。</li></ul><hr><h4 id=2️⃣-用户调用-recv-开始处理>2️⃣ 用户调用 <code>recv</code> 开始处理</h4><ul><li>用户态进入 <code>recv</code> 系统调用，进入内核态的 <code>tcp_recvmsg</code> 。</li><li>内核先检查 <strong>prequeue 队列是否有数据</strong> 。<ul><li>有的话，直接将 prequeue 报文合并进 receive 队列。</li><li>这样节省了一次上下文切换（因为之前没唤醒用户）。</li></ul></li></ul><hr><h4 id=3️⃣-从-receive-队列复制数据>3️⃣ 从 receive 队列复制数据</h4><ul><li>从 receive 队列中按顺序取出 S1-S2 数据，拷贝到用户态缓冲区。</li><li>检查是否达到 <code>SO_RCVLOWAT</code> 阈值：<ul><li>如果还没达到（比如数据太少），继续睡眠。</li><li>如果已达到或数据结束，准备返回。</li></ul></li></ul><hr><h4 id=4️⃣-在等待期间收到新报文-s2-s3-s3-s4>4️⃣ 在等待期间收到新报文（S2-S3、S3-S4）</h4><ul><li>因为用户进程在睡眠，新的报文（S2-S3、S3-S4）会先进入 prequeue。</li><li>当用户态再次被唤醒执行 <code>recv</code> 时，这些报文又被批量搬入 receive 队列。</li></ul><hr><h4 id=5️⃣-一次性拷贝并返回>5️⃣ 一次性拷贝并返回</h4><ul><li>用户态醒来后， <code>recv</code> 直接处理这些已排好序的数据。</li><li>因为前后收的报文都已经连续（S1→S4），可以一次性拷贝完整内容。</li><li>返回给用户 S4-S1 的字节数。</li></ul><hr><h3 id=总体差异总结>总体差异总结</h3><table><thead><tr><th>项目</th><th>当前图（低延迟模式）</th><th>另一类流程（默认高吞吐模式）</th></tr></thead><tbody><tr><td><code>tcp_low_latency</code></td><td>1</td><td>0（默认）</td></tr><tr><td>报文进入队列</td><td>直接进入 receive 队列</td><td>优先放入 prequeue</td></tr><tr><td>用户进程唤醒时机</td><td>报文一到就可能唤醒</td><td>等到用户主动 recv 或积累足够数据</td></tr><tr><td>性能特征</td><td>响应更快、上下文切换多</td><td>吞吐更高、延迟略大</td></tr><tr><td>场景示例</td><td>即时通信、RPC 服务</td><td>文件传输、流式传输</td></tr></tbody></table><p><strong>一句话总结：</strong></p><blockquote><p>低延迟模式：报文来了就马上处理，像电话实时对话。
默认模式：报文积攒一会儿再批量处理，像快递集中派送。</p></blockquote></div><div class=post_comments></div></article><aside class=sidebar><section class=sidebar_inner><br><h2 class=mt-4>Recent Posts</h2><ul class=flex-column><li><a href=https://songronghu.github.io/posts/2025-12-04/ class=nav-link title="TCP 接收报文 流程分析">TCP 接收报文 流程分析</a></li><li><a href=https://songronghu.github.io/posts/2025-12-03/ class=nav-link title="TCP 发送数据 核心流程">TCP 发送数据 核心流程</a></li><li><a href=https://songronghu.github.io/posts/deploy_personal_blog/ class=nav-link title=使用hugo搭建博客>使用hugo搭建博客</a></li><li><a href=https://songronghu.github.io/posts/my-first-blog/ class=nav-link title=我的第一篇博客>我的第一篇博客</a></li></ul><div><h2 class="mt-4 taxonomy" id=categories-section>Categories</h2><nav class=tags_nav><a href=https://songronghu.github.io/categories/%E6%8A%80%E6%9C%AF/ class="post_tag button button_translucent" title=技术>技术
<span class=button_tally>3</span>
</a><a href=https://songronghu.github.io/categories/tcp/ class="post_tag button button_translucent" title=tcp>TCP
<span class=button_tally>1</span>
</a><a href=https://songronghu.github.io/categories// class="post_tag button button_translucent" title=|>|
<span class=button_tally>1</span></a></nav></div><div><h2 class="mt-4 taxonomy" id=tags-section>Tags</h2><nav class=tags_nav><a href=https://songronghu.github.io/tags/blog/ class="post_tag button button_translucent" title=blog>BLOG
<span class=button_tally>3</span>
</a><a href=https://songronghu.github.io/tags/emacs/ class="post_tag button button_translucent" title=emacs>EMACS
<span class=button_tally>1</span></a></nav></div></section></aside></div></main><svg width="0" height="0" class="hidden"><symbol viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" id="facebook"><path d="M437 0H75C33.648.0.0 33.648.0 75v362c0 41.352 33.648 75 75 75h151V331h-60v-90h60v-61c0-49.629 40.371-90 90-90h91v90h-91v61h91l-15 90h-76v181h121c41.352.0 75-33.648 75-75V75c0-41.352-33.648-75-75-75zm0 0"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 18.001 18.001" id="twitter"><path d="M15.891 4.013c.808-.496 1.343-1.173 1.605-2.034a8.68 8.68.0 01-2.351.861c-.703-.756-1.593-1.14-2.66-1.14-1.043.0-1.924.366-2.643 1.078A3.56 3.56.0 008.766 5.383c0 .309.039.585.117.819-3.076-.105-5.622-1.381-7.628-3.837-.34.601-.51 1.213-.51 1.846.0 1.301.549 2.332 1.645 3.089-.625-.053-1.176-.211-1.645-.47.0.929.273 1.705.82 2.388a3.623 3.623.0 002.115 1.291c-.312.08-.641.118-.979.118-.312.0-.533-.026-.664-.083.23.757.664 1.371 1.291 1.841a3.652 3.652.0 002.152.743C4.148 14.173 2.625 14.69.902 14.69c-.422.0-.721-.006-.902-.038 1.697 1.102 3.586 1.649 5.676 1.649 2.139.0 4.029-.542 5.674-1.626 1.645-1.078 2.859-2.408 3.639-3.974a10.77 10.77.0 001.172-4.892v-.468a7.788 7.788.0 001.84-1.921 8.142 8.142.0 01-2.11.593z"/></symbol><symbol aria-hidden="true" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" id="mail"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V4e2c0 26.5-21.5 48-48 48H48c-26.5.0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5.0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" id="calendar"><path d="M452 40h-24V0h-40v40H124V0H84v40H60C26.916 40 0 66.916.0 1e2v352c0 33.084 26.916 60 60 60h392c33.084.0 60-26.916 60-60V1e2c0-33.084-26.916-60-60-60zm20 412c0 11.028-8.972 20-20 20H60c-11.028.0-20-8.972-20-20V188h432v264zm0-304H40v-48c0-11.028 8.972-20 20-20h24v40h40V80h264v40h40V80h24c11.028.0 20 8.972 20 20v48z"/><path d="M76 230h40v40H76zm80 0h40v40h-40zm80 0h40v40h-40zm80 0h40v40h-40zm80 0h40v40h-40zM76 310h40v40H76zm80 0h40v40h-40zm80 0h40v40h-40zm80 0h40v40h-40zM76 390h40v40H76zm80 0h40v40h-40zm80 0h40v40h-40zm80 0h40v40h-40zm80-80h40v40h-40z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" id="github"><path d="M255.968 5.329C114.624 5.329.0 120.401.0 262.353c0 113.536 73.344 209.856 175.104 243.872 12.8 2.368 17.472-5.568 17.472-12.384.0-6.112-.224-22.272-.352-43.712-71.2 15.52-86.24-34.464-86.24-34.464-11.616-29.696-28.416-37.6-28.416-37.6-23.264-15.936 1.728-15.616 1.728-15.616 25.696 1.824 39.2 26.496 39.2 26.496 22.848 39.264 59.936 27.936 74.528 21.344 2.304-16.608 8.928-27.936 16.256-34.368-56.832-6.496-116.608-28.544-116.608-127.008.0-28.064 9.984-51.008 26.368-68.992-2.656-6.496-11.424-32.64 2.496-68 0 0 21.504-6.912 70.4 26.336 20.416-5.696 42.304-8.544 64.096-8.64 21.728.128 43.648 2.944 64.096 8.672 48.864-33.248 70.336-26.336 70.336-26.336 13.952 35.392 5.184 61.504 2.56 68 16.416 17.984 26.304 40.928 26.304 68.992.0 98.72-59.84 120.448-116.864 126.816 9.184 7.936 17.376 23.616 17.376 47.584.0 34.368-.32 62.08-.32 70.496.0 6.88 4.608 14.88 17.6 12.352C438.72 472.145 512 375.857 512 262.353 512 120.401 397.376 5.329 255.968 5.329z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 212 212" id="gitlab"><path d="M12.3 74.7h54L43.3 3c-1-3.6-6.4-3.6-7.6.0L12.3 74.8z"/><path d="M12.3 74.7.5 111c-1 3.2.0 6.8 3 8.8l101.6 74-92.5-119z"/><path d="M105 193.7l-38.6-119h-54l92.7 119z"/><path d="M105 193.7l38.7-119H66.4l38.7 119z"/><path d="M105 193.7l38.7-119H198l-93 119z"/><path d="M198 74.7l11.6 36.2c1 3 0 6.6-3 8.6l-101.5 74 93-119z"/><path d="M198 74.7h-54.3L167 3c1.2-3.6 6.4-3.6 7.6.0L198 74.8z"/></symbol><symbol viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" id="rss"><circle cx="3.429" cy="20.571" r="3.429"/><path d="M11.429 24h4.57C15.999 15.179 8.821 8.001.0 8v4.572c6.302.001 11.429 5.126 11.429 11.428z"/><path d="M24 24C24 10.766 13.234.0.0.0v4.571c10.714.0 19.43 8.714 19.43 19.429z"/></symbol><symbol viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" id="linkedin"><path d="M437 0H75C33.648.0.0 33.648.0 75v362c0 41.352 33.648 75 75 75h362c41.352.0 75-33.648 75-75V75c0-41.352-33.648-75-75-75zM181 406h-60V196h60zm0-240h-60v-60h60zm210 240h-60V286c0-16.54-13.46-30-30-30s-30 13.46-30 30v120h-60V196h60v11.309C286.719 202.422 296.93 196 316 196c40.691.043 75 36.547 75 79.688zm0 0"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 612 612" id="to-top"><path d="M604.501 440.509 325.398 134.956c-5.331-5.357-12.423-7.627-19.386-7.27-6.989-.357-14.056 1.913-19.387 7.27L7.499 440.509c-9.999 10.024-9.999 26.298.0 36.323s26.223 10.024 36.222.0l262.293-287.164L568.28 476.832c9.999 10.024 26.222 10.024 36.221.0 9.999-10.023 9.999-26.298.0-36.323z"/></symbol><symbol viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" id="carly"><path d="M504.971 239.029 448 182.059V84c0-46.317-37.682-84-84-84h-44c-13.255.0-24 10.745-24 24s10.745 24 24 24h44c19.851.0 36 16.149 36 36v108c0 6.365 2.529 12.47 7.029 16.971L454.059 256l-47.029 47.029A24.002 24.002.0 004e2 320v108c0 19.851-16.149 36-36 36h-44c-13.255.0-24 10.745-24 24s10.745 24 24 24h44c46.318.0 84-37.683 84-84v-98.059l56.971-56.971c9.372-9.372 9.372-24.568.0-33.941zM112 192V84c0-19.851 16.149-36 36-36h44c13.255.0 24-10.745 24-24S205.255.0 192 0h-44c-46.318.0-84 37.683-84 84v98.059l-56.971 56.97c-9.373 9.373-9.373 24.568.0 33.941L64 329.941V428c0 46.317 37.682 84 84 84h44c13.255.0 24-10.745 24-24s-10.745-24-24-24h-44c-19.851.0-36-16.149-36-36V320c0-6.365-2.529-12.47-7.029-16.971L57.941 256l47.029-47.029A24.002 24.002.0 00112 192z"/></symbol><symbol viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" id="copy"><path d="M23 2.75A2.75 2.75.0 0020.25.0H8.75A2.75 2.75.0 006 2.75v13.5A2.75 2.75.0 008.75 19h11.5A2.75 2.75.0 0023 16.25zM18.25 14.5h-7.5a.75.75.0 010-1.5h7.5a.75.75.0 010 1.5zm0-3h-7.5a.75.75.0 010-1.5h7.5a.75.75.0 010 1.5zm0-3h-7.5a.75.75.0 010-1.5h7.5a.75.75.0 010 1.5z"/><path d="M8.75 20.5A4.255 4.255.0 014.5 16.25V2.75c0-.086.02-.166.025-.25H3.75A2.752 2.752.0 001 5.25v16A2.752 2.752.0 003.75 24h12a2.752 2.752.0 002.75-2.75v-.75z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512.001 512.001" id="closeme"><path d="M284.286 256.002 506.143 34.144c7.811-7.811 7.811-20.475.0-28.285-7.811-7.81-20.475-7.811-28.285.0L256 227.717 34.143 5.859c-7.811-7.811-20.475-7.811-28.285.0-7.81 7.811-7.811 20.475.0 28.285l221.857 221.857L5.858 477.859c-7.811 7.811-7.811 20.475.0 28.285a19.938 19.938.0 0014.143 5.857 19.94 19.94.0 0014.143-5.857L256 284.287l221.857 221.857c3.905 3.905 9.024 5.857 14.143 5.857s10.237-1.952 14.143-5.857c7.811-7.811 7.811-20.475.0-28.285L284.286 256.002z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" id="open-menu"><path d="M492 236H20c-11.046.0-20 8.954-20 20s8.954 20 20 20h472c11.046.0 20-8.954 20-20s-8.954-20-20-20zm0-160H20C8.954 76 0 84.954.0 96s8.954 20 20 20h472c11.046.0 20-8.954 20-20s-8.954-20-20-20zm0 320H20c-11.046.0-20 8.954-20 20s8.954 20 20 20h472c11.046.0 20-8.954 20-20s-8.954-20-20-20z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" id="instagram"><path d="M12 2.163c3.204.0 3.584.012 4.85.07 3.252.148 4.771 1.691 4.919 4.919.058 1.265.069 1.645.069 4.849.0 3.205-.012 3.584-.069 4.849-.149 3.225-1.664 4.771-4.919 4.919-1.266.058-1.644.07-4.85.07-3.204.0-3.584-.012-4.849-.07-3.26-.149-4.771-1.699-4.919-4.92-.058-1.265-.07-1.644-.07-4.849.0-3.204.013-3.583.07-4.849.149-3.227 1.664-4.771 4.919-4.919 1.266-.057 1.645-.069 4.849-.069zM12 0C8.741.0 8.333.014 7.053.072c-4.358.2-6.78 2.618-6.98 6.98-.059 1.281-.073 1.689-.073 4.948s.014 3.668.072 4.948c.2 4.358 2.618 6.78 6.98 6.98C8.333 23.986 8.741 24 12 24s3.668-.014 4.948-.072c4.354-.2 6.782-2.618 6.979-6.98.059-1.28.073-1.689.073-4.948s-.014-3.667-.072-4.947c-.196-4.354-2.617-6.78-6.979-6.98-1.281-.059-1.69-.073-4.949-.073zm0 5.838c-3.403.0-6.162 2.759-6.162 6.162S8.597 18.163 12 18.163s6.162-2.759 6.162-6.163c0-3.403-2.759-6.162-6.162-6.162zM12 16c-2.209.0-4-1.79-4-4 0-2.209 1.791-4 4-4s4 1.791 4 4c0 2.21-1.791 4-4 4zm6.406-11.845c-.796.0-1.441.645-1.441 1.44s.645 1.44 1.441 1.44c.795.0 1.439-.645 1.439-1.44s-.644-1.44-1.439-1.44z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" id="youtube"><path d="M19.615 3.184c-3.604-.246-11.631-.245-15.23.0-3.897.266-4.356 2.62-4.385 8.816.029 6.185.484 8.549 4.385 8.816 3.6.245 11.626.246 15.23.0C23.512 20.55 23.971 18.196 24 12c-.029-6.185-.484-8.549-4.385-8.816zM9 16V8l8 3.993L9 16z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" id="stackoverflow"><path d="M21 27v-8h3v11H0V19h3v8h18z"/><path d="M17.1.2 15 1.8l7.9 10.6 2.1-1.6L17.1.2zm3.7 14.7L10.6 6.4l1.7-2 10.2 8.5-1.7 2zM7.2 12.3l12 5.6 1.1-2.4-12-5.6-1.1 2.4zm-1.8 6.8 13.56 1.96.17-2.38-13.26-2.55-.47 2.97zM19 25H5v-3h14v3z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" id="xing"><path d="M18.188.0c-.517.0-.741.325-.927.66.0.0-7.455 13.224-7.702 13.657.015.024 4.919 9.023 4.919 9.023.17.308.436.66.967.66h3.454c.211.0.375-.078.463-.22.089-.151.089-.346-.009-.536l-4.879-8.916c-.004-.006-.004-.016.0-.022L22.139.756c.095-.191.097-.387.006-.535C22.056.078 21.894.0 21.686.0h-3.498zM3.648 4.74c-.211.0-.385.074-.473.216-.09.149-.078.339.02.531l2.34 4.05c.004.01.004.016.0.021L1.86 16.051c-.099.188-.093.381.0.529.085.142.239.234.45.234h3.461c.518.0.766-.348.945-.667l3.734-6.609-2.378-4.155c-.172-.315-.434-.659-.962-.659H3.648v.016z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 71 55" id="discord"><path d="M60.1045 4.8978C55.5792 2.8214 50.7265 1.2916 45.6527.41542 45.5603.39851 45.468.440769 45.4204.525289 44.7963 1.6353 44.105 3.0834 43.6209 4.2216c-5.4572-.817-10.8864-.817-16.2317.0C26.905 3.0581 26.1886 1.6353 25.5617.525289 25.5141.443589 25.4218.40133 25.3294.41542c-5.071.87338-9.9237 2.40318-14.4518 4.48238C10.8384 4.9147 10.8048 4.9429 10.7825 4.9795 1.57795 18.7309-.943561 32.1443.293408 45.3914.299005 45.4562.335386 45.5182.385761 45.5576 6.45866 50.0174 12.3413 52.7249 18.1147 54.5195 18.2071 54.5477 18.305 54.5139 18.3638 54.4378 19.7295 52.5728 20.9469 50.6063 21.9907 48.5383 22.0523 48.4172 21.9935 48.2735 21.8676 48.2256 19.9366 47.4931 18.0979 46.6 16.3292 45.5858 16.1893 45.5041 16.1781 45.304 16.3068 45.2082 16.679 44.9293 17.0513 44.6391 17.4067 44.3461 17.471 44.2926 17.5606 44.2813 17.6362 44.3151c11.6196 5.3051 24.1992 5.3051 35.6817.0C53.3935 44.2785 53.4831 44.2898 53.5502 44.3433 53.9057 44.6363 54.2779 44.9293 54.6529 45.2082 54.7816 45.304 54.7732 45.5041 54.6333 45.5858c-1.7687 1.0339-3.6074 1.9073-5.5412 2.637C48.9662 48.2707 48.9102 48.4172 48.9718 48.5383c1.0662 2.0651 2.2836 4.0316 3.6241 5.8967C52.6519 54.5139 52.7526 54.5477 52.845 54.5195c5.8014-1.7946 11.684-4.5021 17.7569-8.9619C70.6551 45.5182 70.6887 45.459 70.6943 45.3942 72.1747 30.0791 68.2147 16.7757 60.1968 4.9823 60.1772 4.9429 60.1437 4.9147 60.1045 4.8978zM23.7259 37.3253c-3.4983.0-6.3808-3.2117-6.3808-7.156s2.8266-7.156 6.3808-7.156c3.5821.0 6.4367 3.2399 6.3807 7.156.0 3.9443-2.8266 7.156-6.3807 7.156zm23.5919.0c-3.4982.0-6.3807-3.2117-6.3807-7.156s2.8265-7.156 6.3807-7.156c3.5822.0 6.4367 3.2399 6.3808 7.156.0 3.9443-2.7986 7.156-6.3808 7.156z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 17 18" id="mastodon"><path fill="#fff" d="m15.054695 9.8859583c-.22611 1.1632697-2.02517 2.4363497-4.09138 2.6830797-1.0774504.12856-2.1382704.24673-3.2694704.19484-1.84996-.0848-3.30971-.44157-3.30971-.44157.0.1801.0111.35157.0333.51194.24051 1.82571 1.81034 1.93508 3.29737 1.98607 1.50088.0514 2.8373104-.37004 2.8373104-.37004l.0617 1.35686s-1.0498104.56374-2.9199404.66742c-1.03124.0567-2.3117-.0259-3.80308-.42069-3.23454998-.85613-3.79081998-4.304-3.87592998-7.8024197-.026-1.03871-.01-2.01815-.01-2.83732.0-3.57732 2.34385998-4.62587996 2.34385998-4.62587996 1.18184-.54277 3.20976-.77101 5.318-.7882499985409h.0518C9.8267646.01719834 11.856025.24547834 13.037775.78824834c0 0 2.34377 1.04855996 2.34377 4.62587996.0.0.0294 2.63937-.32687 4.47183"/><path fill="#000" d="m12.616925 5.6916583v4.3315297h-1.71607V5.8189683c0-.88624-.37289-1.33607-1.1187604-1.33607-.82467.0-1.23799.53361-1.23799 1.58875v2.30122h-1.70594v-2.30122c0-1.05514-.4134-1.58875-1.23808-1.58875-.74587.0-1.11876.44983-1.11876 1.33607v4.2042197h-1.71607V5.6916583c0-.88527.22541-1.58876.67817-2.10922.46689-.52047 1.07833-.78727 1.83735-.78727.87816.0 1.54317.33752 1.98288 1.01267l.42744.71655.42753-.71655c.43961-.67515 1.10463-1.01267 1.9828704-1.01267.75893.0 1.37037.2668 1.83735.78727.45268.52046.67808 1.22395.67808 2.10922"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 600 530" id="bluesky"><path d="m135.72 44.03C202.216 93.951 273.74 195.17 3e2 249.49c26.262-54.316 97.782-155.54 164.28-205.46C512.26 8.009 590-19.862 590 68.825c0 17.712-10.155 148.79-16.111 170.07-20.703 73.984-96.144 92.854-163.25 81.433 117.3 19.964 147.14 86.092 82.697 152.22-122.39 125.59-175.91-31.511-189.63-71.766-2.514-7.3797-3.6904-10.832-3.7077-7.8964-.0174-2.9357-1.1937.51669-3.7077 7.8964-13.714 40.255-67.233 197.36-189.63 71.766-64.444-66.128-34.605-132.26 82.697-152.22-67.108 11.421-142.55-7.4491-163.25-81.433-5.9562-21.282-16.111-152.36-16.111-170.07.0-88.687 77.742-60.816 125.72-24.795z"/><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 48 48" id="ko-fi"><path fill="#fff" d="M4.5 9.8527H32.7947a0 0 0 010 0v19.225a9.07 9.07.0 01-9.07 9.07H13.57a9.07 9.07.0 01-9.07-9.07V9.8527a0 0 0 010 0z"/><path fill="#000" d="M12.197 25.9493l6.45 6.45 6.45-6.45a8.2 8.2.0 002.4016-5.798h0a4.5082 4.5082.0 00-4.212-4.5459 4.4262 4.4262.0 00-4.64 4.4209 4.4261 4.4261.0 00-4.64-4.4209 4.5082 4.5082.0 00-4.212 4.5459h0a8.2 8.2.0 002.4024 5.798z"/><path fill="#fff" d="M32.7947 9.8527H35.73a7.77 7.77.0 010 15.5394H32.7947"/></svg></symbol></svg><footer class=footer><div class="footer_inner wrap pale"><img src=https://songronghu.github.io/icons/apple-touch-icon.png class="icon icon_2 transparent" alt="My Blog"><p>Copyright&nbsp;<span class=year></span>&nbsp;MY BLOG. All Rights Reserved</p><a class=to_top href=#documentTop><svg class="icon"><title>to-top</title><use xlink:href="#to-top"/></svg></a></div></footer><script type=text/javascript src=https://songronghu.github.io/en/js/bundle.9f41e8957746dbf4000a4ae0202eee34b28fe11dddf9f34fa79df3b517193fdf6bcc548f3b5eebbd24d9fdb6a28b171d1eb864b71df27f3466ad183206aa8af4.js integrity="sha512-n0HolXdG2/QACkrgIC7uNLKP4R3d+fNPp53ztRcZP99rzFSPO17rvSTZ/baiixcdHrhktx3yfzRmrRgyBqqK9A==" crossorigin=anonymous></script></body></html>